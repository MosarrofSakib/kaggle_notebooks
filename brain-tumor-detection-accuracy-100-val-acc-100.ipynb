{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/mdmosarrofhossen/brain-tumor-detection-accuracy-100-val-acc-100?scriptVersionId=121464837\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","source":"# Brain Tumor Detection\n\nIn this notebook I will include different types of solutions for brain tumor detection. The dataset is collected from [here](https://www.kaggle.com/datasets/navoneel/brain-mri-images-for-brain-tumor-detection). The solutions are collected from different notebooks. As a learning process, I am collecting different solutions from different notebooks, trying to improve performace of the model and comparing the performance of the different model on this dataset.\n\nWe will use 3 models on this notebook, which are ResNet50v2, VGG19 and InceptionV3. So the contents of the notebook will be as follows,\n\n* Importing libraries\n* Loading Images and creating utility function for data augmentation\n* Image demostration\n* CNN models\n    1. ResNet50V2\n        * Training without data augmentation\n        * Further tune the model with data augmentation   \n    2. VGG19\n        * Training without data augmentation\n        * Further tune the model with data augmentation \n    3. InceptionV3\n        * Training without data augmentation\n        * Further tune the model with data augmentation \n\n\nLet's get started!","metadata":{}},{"cell_type":"markdown","source":"# Importing the libraries\n\n\n* Numpy and pandas for data analysis\n* plotlib and seaborn for data  exploration\n* sklearn metrics for measuring the performance of the model\n* tensorflow and keras for building our models","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.preprocessing.image import ImageDataGenerator\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nnp.random.seed(42)\ntf.random.set_seed(42)","metadata":{"execution":{"iopub.status.busy":"2023-03-08T10:14:46.059961Z","iopub.execute_input":"2023-03-08T10:14:46.060628Z","iopub.status.idle":"2023-03-08T10:14:55.893573Z","shell.execute_reply.started":"2023-03-08T10:14:46.060591Z","shell.execute_reply":"2023-03-08T10:14:55.892419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading Images and creating utility function for data augmentation\n\n\nIn this section we will load our data(images with labels) from our dataset. The initial size(244*244) will be used for ResNet50v2, we will change the size as required for other models.\n\nWe will create two utility function for generating our data to be trained. One is image_gen, which will create train_ds and val_ds without data augmention which will be used for training the model without data augmentation. The other one is augmented_data, which will apply data_augmentation and return augmented data for train_ds which will be used to futher tune our models.","metadata":{}},{"cell_type":"code","source":"#intializing the image size and batch size\nheight = 244\nwidth = 244\nbatch_size=32","metadata":{"execution":{"iopub.status.busy":"2023-03-08T10:15:03.377384Z","iopub.execute_input":"2023-03-08T10:15:03.378105Z","iopub.status.idle":"2023-03-08T10:15:03.38329Z","shell.execute_reply.started":"2023-03-08T10:15:03.378068Z","shell.execute_reply":"2023-03-08T10:15:03.382215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_dir = \"/kaggle/input/brain-mri-images-for-brain-tumor-detection/\"\n\ndef image_gen(height, width):\n    datagen = ImageDataGenerator(\n            rescale=1./255.,\n            validation_split=0.2,\n            )\n    train_ds = datagen.flow_from_directory(\n        dataset_dir,\n        batch_size=batch_size,\n        subset=\"training\",\n        shuffle=True,\n        class_mode=\"binary\",\n        target_size=(height, width),\n        classes={'no': 0., 'yes': 1.}\n    )\n    \n    val_ds = datagen.flow_from_directory(\n        dataset_dir,\n        batch_size=batch_size,\n        subset=\"validation\",\n        shuffle=True,\n        class_mode=\"binary\",\n        target_size=(height, width),\n        classes={'no': 0., 'yes': 1.}\n    )\n    \n    return train_ds, val_ds\n    \n\ndef augmented_data(height, width):\n    datagen = ImageDataGenerator(\n        rescale= 1./255.,\n        width_shift_range= 0.1,\n        height_shift_range=0.1,\n        shear_range=0.1,\n        zoom_range=0.1,\n        rotation_range=30,\n        horizontal_flip=True,\n        brightness_range=(0.5, 1.0)\n    )\n    \n    train_ds = datagen.flow_from_directory(\n        dataset_dir,\n        batch_size=batch_size,\n        shuffle=True,\n        class_mode=\"binary\",\n        target_size=(height, width),\n        classes={'no': 0., 'yes': 1.}\n    )\n    \n    return train_ds\n\ntrain_ds, val_ds = image_gen(height, width)\n\ntotal_images = np.concatenate([train_ds.labels, val_ds.labels])\nprint('\\n\\n',{\"No brain tumor cases\": len(np.where(total_images==0)[0]),\n             \"Brain tumor cases\": len(np.where(total_images==1)[0])})","metadata":{"execution":{"iopub.status.busy":"2023-03-08T10:15:07.470247Z","iopub.execute_input":"2023-03-08T10:15:07.470611Z","iopub.status.idle":"2023-03-08T10:15:07.687419Z","shell.execute_reply.started":"2023-03-08T10:15:07.470582Z","shell.execute_reply":"2023-03-08T10:15:07.686338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Image demostration\n\nDemostrating some of the training data.","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(3,3, figsize=(10,10))\nfig.suptitle(\"Brain Tumor Pictures\")\n\nfor k in range(9):\n    images, labels = train_ds.next()\n    #print(images[0].shape)\n    i, j = k//3, k%3\n    ax[i, j].imshow(images[0])\n    ax[i, j].set_title(f\"label {int(labels[0])}\")\n    ax[i, j].axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-03-08T10:15:11.267714Z","iopub.execute_input":"2023-03-08T10:15:11.268075Z","iopub.status.idle":"2023-03-08T10:15:13.951655Z","shell.execute_reply.started":"2023-03-08T10:15:11.268044Z","shell.execute_reply":"2023-03-08T10:15:13.950424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CNN Models\n\nWe will start training our data with the CNN models(ResNet50V2, VGG19 and InceptionV2). There will be 2 step for each cases. \n\n* Training without data augmentation\n* Further tune the model with augmented data","metadata":{}},{"cell_type":"markdown","source":"# 1. ResNet50V2\n\nWe will use ResNet50V2 pre-trained model from keras. You can read more details about it from [here](https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet_v2/ResNet50V2). We will use the pre-trained model as base model and will build a final segement with a GlobalAveragePooling2D layer, Flatten layer, 2 Dense layer and a Dropout layer. We will use softmax activation for our output layer.","metadata":{}},{"cell_type":"markdown","source":"**Training without data augmentation**","metadata":{}},{"cell_type":"code","source":"from keras.applications import ResNet50V2\nfrom keras.layers import Dense, Flatten, GlobalAveragePooling2D, Dropout\nfrom keras.optimizers import Adam\nfrom keras.models import Sequential, load_model","metadata":{"execution":{"iopub.status.busy":"2023-03-08T10:15:20.850526Z","iopub.execute_input":"2023-03-08T10:15:20.851107Z","iopub.status.idle":"2023-03-08T10:15:20.858583Z","shell.execute_reply.started":"2023-03-08T10:15:20.851068Z","shell.execute_reply":"2023-03-08T10:15:20.855384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Declaring base model\ntf.keras.backend.clear_session()\n\nbase_model = ResNet50V2(input_shape=(244,244,3), include_top=False)\nbase_model.trainable = False\n\nmodel1 = Sequential([\n    base_model, \n    GlobalAveragePooling2D(),\n    Flatten(),\n    Dense(256, activation=\"relu\", kernel_initializer='he_normal'),\n    Dropout(0.3),\n    Dense(2, activation='softmax')\n])\n\nmodel1.compile(optimizer=Adam(), \n               loss=\"sparse_categorical_crossentropy\", \n               metrics=['accuracy'])\n\nmodel1.summary()","metadata":{"execution":{"iopub.status.busy":"2023-03-08T10:15:24.348961Z","iopub.execute_input":"2023-03-08T10:15:24.349667Z","iopub.status.idle":"2023-03-08T10:15:29.820952Z","shell.execute_reply.started":"2023-03-08T10:15:24.34963Z","shell.execute_reply":"2023-03-08T10:15:29.819903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint = tf.keras.callbacks.ModelCheckpoint('model/resnet50v2_best.h5', \n                                                monitor='accuracy', verbose=1, \n                                                mode='max',save_best_only=True)\nearly = tf.keras.callbacks.EarlyStopping(monitor=\"accuracy\", mode=\"max\",restore_best_weights=True, patience=5)\ncallbacks_list = [checkpoint,early]\n\nhistory = model1.fit(train_ds, validation_data=val_ds, epochs=30, callbacks=callbacks_list)","metadata":{"execution":{"iopub.status.busy":"2023-03-08T10:15:37.652222Z","iopub.execute_input":"2023-03-08T10:15:37.653275Z","iopub.status.idle":"2023-03-08T10:16:22.036703Z","shell.execute_reply.started":"2023-03-08T10:15:37.653233Z","shell.execute_reply":"2023-03-08T10:16:22.035723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"his_data = pd.DataFrame(history.history)\nplt.figure(figsize=(20,5))\n\nplt.subplot(1,2,1)\nplt.plot(his_data.loss, label=\"Training loss\")\nplt.plot(his_data.val_loss, label=\"Validation loss\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"loss\")\nplt.title(\"Losses\")\nplt.grid()\nplt.legend()\n\nplt.subplot(1,2,2)\nplt.plot(his_data.accuracy, label=\"Training accuracy\")\nplt.plot(his_data.val_accuracy, label=\"Validation accuracy\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"Accuracy\")\nplt.grid()\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2023-03-08T10:16:28.299923Z","iopub.execute_input":"2023-03-08T10:16:28.300309Z","iopub.status.idle":"2023-03-08T10:16:28.770275Z","shell.execute_reply.started":"2023-03-08T10:16:28.300274Z","shell.execute_reply":"2023-03-08T10:16:28.768168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Further tune the model with augmented data**\n\nWe will use our augmented_data utility function to load augmented training data. Here we are using a callback function(reduce_lr) to decrease learning rate if the accuracy doesn't improve for 2 epochs.","metadata":{}},{"cell_type":"code","source":"aug_train_ds = augmented_data(height, width)\n\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='accuracy', factor=0.3,\n                                                 patience=2, min_lr=0.0000001)\ncallbacks_list = [checkpoint,early,reduce_lr]\n\nhistory = model1.fit(aug_train_ds, validation_data=val_ds, epochs=30, callbacks=callbacks_list)","metadata":{"execution":{"iopub.status.busy":"2023-03-08T10:16:38.408156Z","iopub.execute_input":"2023-03-08T10:16:38.409175Z","iopub.status.idle":"2023-03-08T10:18:19.945674Z","shell.execute_reply.started":"2023-03-08T10:16:38.409111Z","shell.execute_reply":"2023-03-08T10:18:19.944706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"his_data = pd.DataFrame(history.history)\nplt.figure(figsize=(20,5))\n\nplt.subplot(1,2,1)\nplt.plot(his_data.loss, label=\"Training loss\")\nplt.plot(his_data.val_loss, label=\"Validation loss\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"loss\")\nplt.title(\"Losses\")\nplt.grid()\nplt.legend()\n\nplt.subplot(1,2,2)\nplt.plot(his_data.accuracy, label=\"Training accuracy\")\nplt.plot(his_data.val_accuracy, label=\"Validation accuracy\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"Accuracy\")\nplt.grid()\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2023-03-08T10:18:56.360697Z","iopub.execute_input":"2023-03-08T10:18:56.361066Z","iopub.status.idle":"2023-03-08T10:18:56.805093Z","shell.execute_reply.started":"2023-03-08T10:18:56.361032Z","shell.execute_reply":"2023-03-08T10:18:56.804106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_result = model1.evaluate(train_ds)\nval_result = model1.evaluate(val_ds)\n\nmodel1_result = pd.DataFrame(zip(train_result, val_result), \n                             columns=['Train', 'Validation'], \n                             index=['Loss', \"Accuracy\"])\n\nmodel1_result","metadata":{"execution":{"iopub.status.busy":"2023-03-08T10:19:07.913963Z","iopub.execute_input":"2023-03-08T10:19:07.914371Z","iopub.status.idle":"2023-03-08T10:19:09.613834Z","shell.execute_reply.started":"2023-03-08T10:19:07.914336Z","shell.execute_reply":"2023-03-08T10:19:09.612903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model1.predict(val_ds[0][0])\ny_pred = np.argmax(y_pred, axis=-1)\n\ny_test = val_ds[0][-1]\n\n#print(y_pred.shape)\n#print(y_test.shape)\nprint(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\nprint(\"Accuracy Score: \", accuracy_score(y_test,y_pred))\nprint(\"Classification report:\\n\", classification_report(y_pred,y_test))","metadata":{"execution":{"iopub.status.busy":"2023-03-08T10:19:15.587944Z","iopub.execute_input":"2023-03-08T10:19:15.588318Z","iopub.status.idle":"2023-03-08T10:19:16.845075Z","shell.execute_reply.started":"2023-03-08T10:19:15.588286Z","shell.execute_reply":"2023-03-08T10:19:16.843883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(confusion_matrix(y_test, y_pred), annot=True)","metadata":{"execution":{"iopub.status.busy":"2023-03-08T10:19:24.126256Z","iopub.execute_input":"2023-03-08T10:19:24.126975Z","iopub.status.idle":"2023-03-08T10:19:24.37589Z","shell.execute_reply.started":"2023-03-08T10:19:24.126938Z","shell.execute_reply":"2023-03-08T10:19:24.374922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. VGG19\n\nWe will use VGG19 pre-trained model from keras. You can read more details about it from [here](https://keras.io/api/applications/vgg/). We will use the pre-trained model as base model and will build a final segement with a Flatten layer and a Dense layer. We will use sigmoid activation for our output layer. For VGG19, we will use image size of 224*224.","metadata":{}},{"cell_type":"markdown","source":"**Training without data augmentation**","metadata":{}},{"cell_type":"code","source":"from keras.applications.vgg19 import VGG19","metadata":{"execution":{"iopub.status.busy":"2023-03-08T10:19:31.920867Z","iopub.execute_input":"2023-03-08T10:19:31.921285Z","iopub.status.idle":"2023-03-08T10:19:31.926851Z","shell.execute_reply.started":"2023-03-08T10:19:31.921247Z","shell.execute_reply":"2023-03-08T10:19:31.925661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.backend.clear_session()\n\n#initializing new height and width for images\nheight=224\nwidth=224\n\ntrain_ds, val_ds = image_gen(height, width)\n\nbase_model = VGG19(\n    weights='imagenet',\n    include_top=False,\n    input_shape=(height,width,3)\n)\n\nbase_model.trainable = False\n\nmodel2 = Sequential([\n    base_model,\n    #GlobalAveragePooling2D(),\n    Flatten(),\n    #Dense(256, activation=\"relu\", kernel_initializer='he_normal'),\n    Dense(1, activation='sigmoid')\n])\n\nmodel2.summary()","metadata":{"execution":{"iopub.status.busy":"2023-03-08T10:19:34.369432Z","iopub.execute_input":"2023-03-08T10:19:34.370141Z","iopub.status.idle":"2023-03-08T10:19:35.673707Z","shell.execute_reply.started":"2023-03-08T10:19:34.370087Z","shell.execute_reply":"2023-03-08T10:19:35.672913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model2.compile(loss=\"binary_crossentropy\", \n               optimizer=Adam(0.01), metrics=['accuracy'])\n\ncheckpoint = tf.keras.callbacks.ModelCheckpoint('model/vgg19_best.h5', \n                                                monitor='accuracy', verbose=1, \n                                                mode='max',save_best_only=True)\nearly = tf.keras.callbacks.EarlyStopping(monitor=\"accuracy\", mode=\"max\",\n                                         restore_best_weights=True, patience=5)\ncallbacks_list = [checkpoint,early]\n\nhistory = model2.fit(train_ds, \n           validation_data=val_ds,\n           epochs=30,\n           shuffle=True,\n           verbose=True,\n           callbacks=callbacks_list\n          )","metadata":{"execution":{"iopub.status.busy":"2023-03-08T10:19:40.4747Z","iopub.execute_input":"2023-03-08T10:19:40.47506Z","iopub.status.idle":"2023-03-08T10:20:32.991561Z","shell.execute_reply.started":"2023-03-08T10:19:40.47503Z","shell.execute_reply":"2023-03-08T10:20:32.990519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"his_data = pd.DataFrame(history.history)\nplt.figure(figsize=(20,5))\n\nplt.subplot(1,2,1)\nplt.plot(his_data.loss, label=\"Training loss\")\nplt.plot(his_data.val_loss, label=\"Validation loss\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"loss\")\nplt.title(\"Losses\")\nplt.grid()\nplt.legend()\n\nplt.subplot(1,2,2)\nplt.plot(his_data.accuracy, label=\"Training accuracy\")\nplt.plot(his_data.val_accuracy, label=\"Validation accuracy\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"Accuracy\")\nplt.grid()\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2023-03-08T10:20:44.817479Z","iopub.execute_input":"2023-03-08T10:20:44.817849Z","iopub.status.idle":"2023-03-08T10:20:45.407547Z","shell.execute_reply.started":"2023-03-08T10:20:44.817817Z","shell.execute_reply":"2023-03-08T10:20:45.406468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Further tune the model with augmented data**\n\nWe will use our augmented_data utility function to load augmented training data. Here we are using a callback function(reduce_lr) to decrease learning rate if the accuracy doesn't improve for 2 epochs.","metadata":{}},{"cell_type":"code","source":"aug_train_ds = augmented_data(height, width)\n\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='accuracy', \n                                                 factor=0.3,patience=2, \n                                                 min_lr=0.0000001)\ncallbacks_list = [checkpoint,early, reduce_lr]\n\nhistory = model2.fit(aug_train_ds, \n           validation_data=val_ds,\n           epochs=30,\n           shuffle=True,\n           verbose=True,\n           callbacks=callbacks_list\n          )","metadata":{"execution":{"iopub.status.busy":"2023-03-08T10:20:50.778046Z","iopub.execute_input":"2023-03-08T10:20:50.779049Z","iopub.status.idle":"2023-03-08T10:23:02.069524Z","shell.execute_reply.started":"2023-03-08T10:20:50.77901Z","shell.execute_reply":"2023-03-08T10:23:02.06846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"his_data = pd.DataFrame(history.history)\nplt.figure(figsize=(20,5))\n\nplt.subplot(1,2,1)\nplt.plot(his_data.loss, label=\"Training loss\")\nplt.plot(his_data.val_loss, label=\"Validation loss\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"loss\")\nplt.title(\"Losses\")\nplt.grid()\nplt.legend()\n\nplt.subplot(1,2,2)\nplt.plot(his_data.accuracy, label=\"Training accuracy\")\nplt.plot(his_data.val_accuracy, label=\"Validation accuracy\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"Accuracy\")\nplt.grid()\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2023-03-08T10:23:12.107387Z","iopub.execute_input":"2023-03-08T10:23:12.107866Z","iopub.status.idle":"2023-03-08T10:23:12.54389Z","shell.execute_reply.started":"2023-03-08T10:23:12.107828Z","shell.execute_reply":"2023-03-08T10:23:12.542978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_result = model2.evaluate(train_ds)\nval_result = model2.evaluate(val_ds)\n\nmodel2_result = pd.DataFrame(zip(train_result, val_result), \n                             columns=['Train', 'Validation'], \n                             index=['Loss', \"Accuracy\"])\n\nmodel2_result","metadata":{"execution":{"iopub.status.busy":"2023-03-08T10:23:19.074171Z","iopub.execute_input":"2023-03-08T10:23:19.074867Z","iopub.status.idle":"2023-03-08T10:23:20.967829Z","shell.execute_reply.started":"2023-03-08T10:23:19.074828Z","shell.execute_reply":"2023-03-08T10:23:20.966665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model2.predict(val_ds[0][0])\ny_pred = np.array([1 if x > 0.5 else 0 for x in y_pred])\n\ny_test = val_ds[0][-1]\n\n#print(y_pred.shape)\n#print(y_test.shape)\nprint(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\nprint(\"Accuracy Score: \", accuracy_score(y_test,y_pred))\nprint(\"Classification report:\\n\", classification_report(y_pred,y_test))","metadata":{"execution":{"iopub.status.busy":"2023-03-08T10:23:24.924637Z","iopub.execute_input":"2023-03-08T10:23:24.924999Z","iopub.status.idle":"2023-03-08T10:23:25.560931Z","shell.execute_reply.started":"2023-03-08T10:23:24.924968Z","shell.execute_reply":"2023-03-08T10:23:25.559817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(confusion_matrix(y_test, y_pred), annot=True)","metadata":{"execution":{"iopub.status.busy":"2023-03-08T10:23:30.144955Z","iopub.execute_input":"2023-03-08T10:23:30.146054Z","iopub.status.idle":"2023-03-08T10:23:30.394176Z","shell.execute_reply.started":"2023-03-08T10:23:30.146006Z","shell.execute_reply":"2023-03-08T10:23:30.393248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. InceptionV3\n\nWe will use InceptionV3 pre-trained model from keras. You can read more details about it from [here](https://keras.io/api/applications/inceptionv3/). We will use the pre-trained model as base model and will build a final segement with a Flatten layer and a Dense layer. We will use sigmoid activation for our output layer.","metadata":{}},{"cell_type":"markdown","source":"**Training without data augmentation**","metadata":{}},{"cell_type":"code","source":"from keras.applications import InceptionV3","metadata":{"execution":{"iopub.status.busy":"2023-03-08T10:23:34.817042Z","iopub.execute_input":"2023-03-08T10:23:34.817752Z","iopub.status.idle":"2023-03-08T10:23:34.822725Z","shell.execute_reply.started":"2023-03-08T10:23:34.817713Z","shell.execute_reply":"2023-03-08T10:23:34.821475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"height=299\nwidth=299\n\ntrain_ds, val_ds = image_gen(height, width)\n\ntf.keras.backend.clear_session()\n\nbase_model = InceptionV3(\n    input_shape=(height, width,3),\n    weights='imagenet',\n    include_top=False\n)\n\nbase_model.trainable = False\n\nmodel3 = Sequential([\n    base_model,\n    Flatten(),\n    Dense(1, activation='sigmoid')\n])\n\nmodel3.compile(loss=\"binary_crossentropy\", optimizer=Adam(0.01), metrics=['accuracy'])\n\nmodel3.summary()","metadata":{"execution":{"iopub.status.busy":"2023-03-08T10:23:45.397909Z","iopub.execute_input":"2023-03-08T10:23:45.398621Z","iopub.status.idle":"2023-03-08T10:23:49.501263Z","shell.execute_reply.started":"2023-03-08T10:23:45.398583Z","shell.execute_reply":"2023-03-08T10:23:49.500071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint = tf.keras.callbacks.ModelCheckpoint('model/inceptionv3_best.h5', \n                                                monitor='accuracy', verbose=1, \n                                                mode='max',save_best_only=True)\nearly = tf.keras.callbacks.EarlyStopping(monitor=\"accuracy\", mode=\"max\",\n                                         restore_best_weights=True, patience=5)\n\ncallback_lsit = [checkpoint, early]\n\nhistory = model3.fit(train_ds, validation_data=val_ds, epochs=30, callbacks=callback_lsit)","metadata":{"execution":{"iopub.status.busy":"2023-03-08T10:23:53.132713Z","iopub.execute_input":"2023-03-08T10:23:53.133077Z","iopub.status.idle":"2023-03-08T10:24:59.230771Z","shell.execute_reply.started":"2023-03-08T10:23:53.133043Z","shell.execute_reply":"2023-03-08T10:24:59.22967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"his_data = pd.DataFrame(history.history)\nplt.figure(figsize=(20,5))\n\nplt.subplot(1,2,1)\nplt.plot(his_data.loss, label=\"Training loss\")\nplt.plot(his_data.val_loss, label=\"Validation loss\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"loss\")\nplt.title(\"Losses\")\nplt.grid()\nplt.legend()\n\nplt.subplot(1,2,2)\nplt.plot(his_data.accuracy, label=\"Training accuracy\")\nplt.plot(his_data.val_accuracy, label=\"Validation accuracy\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"Accuracy\")\nplt.grid()\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2023-03-08T10:26:08.674281Z","iopub.execute_input":"2023-03-08T10:26:08.67537Z","iopub.status.idle":"2023-03-08T10:26:09.106991Z","shell.execute_reply.started":"2023-03-08T10:26:08.675328Z","shell.execute_reply":"2023-03-08T10:26:09.106067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Further tune the model with augmented data**\n\nWe will use our augmented_data utility function to load augmented training data. Here we are using a callback function(reduce_lr) to decrease learning rate if the accuracy doesn't improve for 3 epochs.","metadata":{}},{"cell_type":"code","source":"aug_train_ds = augmented_data(height, width)\n\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='accuracy', factor=0.3,\n                              patience=3, min_lr=0.0000001)\ncallback_lsit = [checkpoint, early, reduce_lr]\n\nhistory = model3.fit(aug_train_ds, validation_data=val_ds, epochs=30, callbacks=callback_lsit)","metadata":{"execution":{"iopub.status.busy":"2023-03-08T10:26:14.903422Z","iopub.execute_input":"2023-03-08T10:26:14.903776Z","iopub.status.idle":"2023-03-08T10:29:48.018657Z","shell.execute_reply.started":"2023-03-08T10:26:14.903746Z","shell.execute_reply":"2023-03-08T10:29:48.017702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"his_data = pd.DataFrame(history.history)\nplt.figure(figsize=(20,5))\n\nplt.subplot(1,2,1)\nplt.plot(his_data.loss, label=\"Training loss\")\nplt.plot(his_data.val_loss, label=\"Validation loss\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"loss\")\nplt.title(\"Losses\")\nplt.grid()\nplt.legend()\n\nplt.subplot(1,2,2)\nplt.plot(his_data.accuracy, label=\"Training accuracy\")\nplt.plot(his_data.val_accuracy, label=\"Validation accuracy\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"Accuracy\")\nplt.grid()\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2023-03-08T10:29:54.106317Z","iopub.execute_input":"2023-03-08T10:29:54.106682Z","iopub.status.idle":"2023-03-08T10:29:54.549065Z","shell.execute_reply.started":"2023-03-08T10:29:54.106651Z","shell.execute_reply":"2023-03-08T10:29:54.548041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_result = model3.evaluate(train_ds)\nval_result = model3.evaluate(val_ds)\n\nmodel3_result = pd.DataFrame(zip(train_result, val_result), \n                             columns=['Train', 'Validation'], \n                             index=['Loss', \"Accuracy\"])\n\nmodel3_result","metadata":{"execution":{"iopub.status.busy":"2023-03-08T10:29:58.948729Z","iopub.execute_input":"2023-03-08T10:29:58.949353Z","iopub.status.idle":"2023-03-08T10:30:02.049315Z","shell.execute_reply.started":"2023-03-08T10:29:58.949308Z","shell.execute_reply":"2023-03-08T10:30:02.048085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model3.predict(val_ds[0][0])\ny_pred = np.array([1 if x > 0.5 else 0 for x in y_pred])\n\ny_test = val_ds[0][-1]\n\n#print(y_pred.shape)\n#print(y_test.shape)\nprint(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\nprint(\"Accuracy Score: \", accuracy_score(y_test,y_pred))\nprint(\"Classification report:\\n\", classification_report(y_pred,y_test))","metadata":{"execution":{"iopub.status.busy":"2023-03-08T10:30:06.581417Z","iopub.execute_input":"2023-03-08T10:30:06.5818Z","iopub.status.idle":"2023-03-08T10:30:08.167784Z","shell.execute_reply.started":"2023-03-08T10:30:06.581767Z","shell.execute_reply":"2023-03-08T10:30:08.166699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(confusion_matrix(y_test, y_pred), annot=True)","metadata":{"execution":{"iopub.status.busy":"2023-03-08T10:30:16.079098Z","iopub.execute_input":"2023-03-08T10:30:16.079831Z","iopub.status.idle":"2023-03-08T10:30:16.3231Z","shell.execute_reply.started":"2023-03-08T10:30:16.079793Z","shell.execute_reply":"2023-03-08T10:30:16.32213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion\n\nWe have a great results on our all three models. With data augmentation, we have increased the validation accuracy(val_accuray) significatly also reduced over-fitting to the training dataset. Since we had a really small dataset, the models might overfit to the train and validation data which can be reduced by adding more data. Overall we have achieved a great results.\n\nA little comparison between the three models:\n\n\n                    train_Accuracy   val_accuracy    f1_score\n\n1. ResNet50V2:\n                        \n                         99%            ~96%          0.97\n2. VGG19:\n\n                        100%           ~100%          1.00                        \n3. InceptionV3:\n\n                        100%           ~98%          1.00\n\nPlease upvote if you like this notebook. Thank you!","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}